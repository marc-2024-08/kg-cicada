# Data Mesh
## Apache Beam
The unified program model for defining both batch and streaming data-parallel processing pipelines as well as a set of language-specific SDKs for constructing pipelines and Runners for executing them on distributed processing backends, including Apache Flink, Apache Spark, Google Cloud Dataflow and Hazelcast Jet.
GitHub site: https://github.com/apache/beam
Official web site: https://beam.apache.org/

## Project Review Model 
GRAI | PDCA | SMART
---|---|---
Goal/回顾目标: 写下最初定下的目标<br>- 回顾why：当初为什么做这件事？<br>- 回顾what：要达成的目标是什么？关键结果是什么？| Plan/计划: 定计划，排优先级，资源调配，预判结果<br>- Who will complete what when<br>- Goal, what's resources, what's result | 
Result/评估结果: 用结果和目标做对比<br>- 结果在哪个层级？<br>- 哪些超出了预期？<br>- 哪些做的还不够？| Do/执行: 执行计划<br>- List effience steps and methods that can complete the plan<br>- Just do it! | 
Analysis/分析原因: 根据结果分析原因<br>- 做成了是因为什么？<br>- 为什么没做好？ | Check/检查结果: 检查结果<br>- Check every things that are assigned already |
Insight/总结规律: 总结经验和规律<br>- 一开始要注意什么？<br>- 哪些事应该避免？<br>- 遇到什么情况应止损？ | Action/处理: 总结问题，新问题<br>- Success experiences should have a process and reusable<br>- New problem must trasnfer to next iteration

# Resume
## Basic Personal Information
Name:       Xin Yu Pan      
Sex:        Male  
Cell Phone: 18500852935  
Email:      pxy0592@msn.com  

## IBM Company [2012.01 until now]
### DPH Product     Backend development team as team leader     2024.03 to ~
#### Service ID replacement for relevant data assets
Summary: It's security enhancement. The service ID and it's api key as credential are used to communicate between services in DPH instance. They are created at DPH instance initiaulization. At meantime, users can easily delete it by accident. Once the credential is lost, lots of basic fundational in DPH would be lost as well.  
Archievement: I individually completed this project within one week for design, two weeks for coding, and one week for unit testing.  
Technical Stack: Microservice, API Key Management, DevOps, Kubernetes, OpenShift,  
Technical Role: feature developer in backend side     
Program Languages: Java, JUnit, Ansible, Helm Chart, Shell, Jenkins  
Skills: English communication, Time&Risk management

#### Access control based on users or user groups for the data as product access
Brief: This big Epic intend to provide fune-tune access control based on users or user groups for the data assets. There are composed of multiple tasks to complete this Epic. The 1st task was completed already by Indian folks lead by me, and the 2nd task are in design phase, I'm discussing the architecutre, scenarios, use cases with PM, Architecure located in NA.  
Technical Stack: Microservice, Access control management, DevOps, Kubernetes, OpenShift
Technical Role: Feature designer/micro-architecture, developer in backend side     
Program Languages: Java, JUnit, Ansible, Helm Chart, Shell, Jenkins      
Skills: English communication, Time&Risk&Task management     

#### Adapt the DPH product service into Cloud Pak for Data on-prem
Brief:  
Technical Stack:     
Technical Role:     
Program Languages:      
Skills:     

### IBM Global Search Service        Backend development team as team leader     2019.06 to 2024.02
Brief:  
Technical Stack:     
Technical Role:     
Program Languages:      
Skills:     

### IBM High Distributed Performance Cluster         Quality insurence team as team leader   2012.01 to 2019.05
Brief:  
Technical Stack:     
Technical Role:     
Program Languages:      
Skills:     
